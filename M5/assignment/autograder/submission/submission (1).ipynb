{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8face78",
   "metadata": {},
   "source": [
    "<img src=\"https://learn.deeplearning.ai/assets/dlai-logo.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22711013",
   "metadata": {},
   "source": [
    "# Agentic Workflows\n",
    "\n",
    "## Pattern For Highly Autonomous Agents - Planning Workflows\n",
    "\n",
    "In this lab, you will build an agentic system that generates a short research report through planning, external tool usage, and feedback integration. Your workflow will involve:\n",
    "\n",
    "### üë• Agents\n",
    "\n",
    "* **Planning Agent / Writer**: Creates an outline and coordinates tasks.\n",
    "* **Research Agent**: Gathers external information using tools like Arxiv, Tavily, and Wikipedia.\n",
    "* **Editor Agent**: Reflects on the report and provides suggestions for improvement.\n",
    "\n",
    "### üß∞ Available Tools\n",
    "\n",
    "You have access to:\n",
    "\n",
    "* `arxiv_search_tool()`\n",
    "* `tavily_search_tool()`\n",
    "* `wikipedia_search_tool()`\n",
    "\n",
    "Each tool can be called as part of an agent workflow. They are already implemented and available to call.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Objective\n",
    "\n",
    "Implement a function `generate_research_report(prompt: str) -> dict` that orchestrates the full workflow:\n",
    "\n",
    "1. The **planner agent** creates a research plan.\n",
    "2. The **research agent** fetches external content based on the plan.\n",
    "3. The **planner** writes a first draft.\n",
    "4. The **editor agent** reflects on the draft and provides feedback.\n",
    "5. The **planner** revises the draft using the feedback.\n",
    "\n",
    "You should use **tool calls** and **reasoning steps** where appropriate. Don‚Äôt hard-code any queries, the agents should generate them dynamically.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Evaluation\n",
    "\n",
    "You‚Äôll be graded based on:\n",
    "\n",
    "* Whether each agent's function executes correctly.\n",
    "* Whether the response type from each step is a valid string or dictionary.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Starter Functions\n",
    "\n",
    "You'll use this tool mapping and definitions (already provided in `research_tools.py`): \n",
    "\n",
    "### üß∞ Research Tools\n",
    "\n",
    "By importing `research_tools`, you gain access to several search utilities:\n",
    "\n",
    "- `research_tools.arxiv_search_tool(query)` ‚Üí search academic papers from **arXiv**  \n",
    "  *Example:* `research_tools.arxiv_search_tool(\"neural networks for climate modeling\")`\n",
    "\n",
    "- `research_tools.tavily_search_tool(query)` ‚Üí perform web searches with the **Tavily API**  \n",
    "  *Example:* `research_tools.tavily_search_tool(\"latest trends in sunglasses fashion\")`\n",
    "\n",
    "- `research_tools.wikipedia_search_tool(query)` ‚Üí retrieve summaries from **Wikipedia**  \n",
    "  *Example:* `research_tools.wikipedia_search_tool(\"Ensemble Kalman Filter\")`\n",
    "\n",
    "Run the cell below to make them available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9723175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "\n",
    "# --- Standard library \n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "\n",
    "\n",
    "# --- Third-party ---\n",
    "from IPython.display import Markdown, display\n",
    "from aisuite import Client\n",
    "\n",
    "# --- Local / project ---\n",
    "import research_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc8d9c",
   "metadata": {},
   "source": [
    "### ü§ñ Initialize client\n",
    "\n",
    "Create a shared client instance for upcoming calls.\n",
    "\n",
    "`client = Client()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e42f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89313f5",
   "metadata": {},
   "source": [
    "### üß† Exercise 1: Implement the Planner Agent\n",
    "\n",
    "Create a function called `planner_agent(topic: str) -> List[str]` that generates a **step-by-step research plan** as a Python list of strings.\n",
    "\n",
    "Each step must:\n",
    "\n",
    "* Be executable by one of the available agents (`research_agent`, `writer_agent`, `editor_agent`).\n",
    "* Be clearly written and atomic (not a compound task).\n",
    "* Avoid unrelated tasks like file handling or installing packages.\n",
    "* End with a final step that **generates a Markdown document** with the research report.\n",
    "\n",
    "‚úÖ Use the following model: `\"openai:o4-mini\"`\n",
    "‚úÖ Use a temperature of `1.0` to allow creative planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be1add0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def planner_agent(topic: str, model: str = \"openai:o4-mini\") -> list[str]:\n",
    "    \"\"\"\n",
    "    Generates a plan as a Python list of steps (strings) for a research workflow.\n",
    "\n",
    "    Args:\n",
    "        topic (str): Research topic to investigate.\n",
    "        model (str): Language model to use.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of executable step strings.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are a planning agent responsible for organizing a research workflow with multiple intelligent agents.\n",
    "\n",
    "üß† Available agents:\n",
    "- A research agent who can search the web, Wikipedia, and arXiv.\n",
    "- A writer agent who can draft research summaries.\n",
    "- An editor agent who can reflect and revise the drafts.\n",
    "\n",
    "üéØ Your job is to write a clear, step-by-step research plan **as a valid Python list**, where each step is a string.\n",
    "Each step should be atomic, executable, and must rely only on the capabilities of the above agents.\n",
    "\n",
    "üö´ DO NOT include irrelevant tasks like \"create CSV\", \"set up a repo\", \"install packages\", etc.\n",
    "‚úÖ DO include real research-related tasks (e.g., search, summarize, draft, revise).\n",
    "‚úÖ DO assume tool use is available.\n",
    "‚úÖ DO NOT include explanation text ‚Äî return ONLY the Python list.\n",
    "‚úÖ The final step should be to generate a Markdown document containing the complete research report.\n",
    "\n",
    "Topic: \"{topic}\"\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=1,\n",
    "    )\n",
    "\n",
    "    # ‚ö†Ô∏è Evaluate only if the environment is safe\n",
    "    steps = eval(response.choices[0].message.content.strip())\n",
    "    return steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ac71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = planner_agent(\"The ensemble Kalman filter for time series forecasting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14588d4c",
   "metadata": {},
   "source": [
    "### üîç Exercise 2: Implement the Research Agent\n",
    "\n",
    "Complete the function by replacing all `None` values with the correct arguments:\n",
    "\n",
    "* Use the provided `model` and `messages`.\n",
    "* Pass the tool definitions (`arxiv_search_tool`, `tavily_search_tool`, `wikipedia_search_tool`).\n",
    "* Enable tool calls automatically with `tool_choice=\"auto\"`.\n",
    "* Limit to **12 iterations** (`max_turns=12`).\n",
    "* Return the assistant‚Äôs final message content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_agent(task: str, model: str = \"openai:gpt-4o\", return_messages: bool = False):\n",
    "    \"\"\"\n",
    "    Ejecuta una tarea de investigaci√≥n usando herramientas con aisuite (sin bucle manual).\n",
    "    \"\"\"\n",
    "    print(\"==================================\")\n",
    "    print(\"üîç Research Agent\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a research assistant with access to the following tools:\n",
    "- arxiv_tool: for finding academic papers\n",
    "- tavily_tool: for general web search\n",
    "- wikipedia_tool: for encyclopedic knowledge\n",
    "\n",
    "Task:\n",
    "{task}\n",
    "\n",
    "Today is {datetime.now().strftime('%Y-%m-%d')}.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt.strip()}]\n",
    "    tools = [research_tools.arxiv_search_tool, research_tools.tavily_search_tool, research_tools.wikipedia_search_tool]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            max_turns=12  # üîÅ The model can use tools multiple times\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        print(\"‚úÖ Output:\\n\", content)\n",
    "        return (content, messages) if return_messages else content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Error:\", e)\n",
    "        return f\"[Model Error: {str(e)}]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313fa83",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise 3: Implement the Writer Agent\n",
    "\n",
    "Create a function `writer_agent(task: str) -> str` that handles writing tasks like drafting sections or summarizing content.\n",
    "\n",
    "Your implementation must:\n",
    "\n",
    "* Use the **`client.chat.completions.create()`** interface.\n",
    "* Include a system prompt:\n",
    "  `\"You are a writing agent specialized in generating well-structured academic or technical content.\"`\n",
    "* Use `temperature=1.0` for creativity.\n",
    "* Set the **default model to `o4-mini`**.\n",
    "* Return the final content from the assistant message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b34a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: writer_agent\n",
    "### START CODE HERE ###\n",
    "def writer_agent(task: str, model: str = \"openai:gpt-4o\") -> str: # @REPLACE def writer_agent(task: str, model: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Executes writing tasks, such as drafting, expanding, or summarizing text.\n",
    "    \"\"\"\n",
    "    print(\"==================================\")\n",
    "    print(\"‚úçÔ∏è Writer Agent\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    \n",
    "    messages = [ # @KEEP messages = [\n",
    "        {\n",
    "            \"role\": \"system\", # @KEEP \"role\": \"system\",\n",
    "            \"content\": \"You are a writing agent specialized in generating well-structured academic or technical content.\" # @REPLACE \"content\": None\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", # @KEEP \"role\": \"user\",\n",
    "            \"content\": task # @REPLACE \"content\": None\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create( # @KEEP response = client.chat.completions.create(\n",
    "        model=model, # @REPLACE model=None,\n",
    "        messages=messages, # @REPLACE messages=None,\n",
    "        temperature=1.0 # @REPLACE temperature=None\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918fa15",
   "metadata": {},
   "source": [
    "### üß† Exercise 4: Implement the Editor Agent\n",
    "\n",
    "Complete the function `editor_agent(task: str) -> str` by replacing all `None` values with the correct arguments.\n",
    "\n",
    "Your implementation must:\n",
    "\n",
    "* Call **`client.chat.completions.create()`**.\n",
    "* Define `messages` with:\n",
    "\n",
    "  * A **system prompt**:\n",
    "    `\"You are an editor agent. Your job is to reflect on, critique, or improve existing drafts.\"`\n",
    "  * A **user prompt** containing the `task`.\n",
    "* Use `temperature=0.7`.\n",
    "* Set the **default model to `o4-mini`**.\n",
    "* Return the assistant‚Äôs final message content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f4928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: editor_agent\n",
    "### START CODE HERE ###\n",
    "def editor_agent(task: str, model: str = \"openai:gpt-4o\") -> str:  # @REPLACE def editor_agent(task: str, model: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Executes editorial tasks such as reflection, critique, or revision.\n",
    "    \"\"\"\n",
    "    print(\"==================================\")\n",
    "    print(\"üß† Editor Agent\")\n",
    "    print(\"==================================\")\n",
    "    \n",
    "    messages = [  # @KEEP messages = [\n",
    "        {\n",
    "            \"role\": \"system\",  # @KEEP \"role\": \"system\",\n",
    "            \"content\": \"You are an editor agent. Your job is to reflect on, critique, or improve existing drafts.\"  # @REPLACE \"content\": None\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",  # @KEEP \"role\": \"user\",\n",
    "            \"content\": task  # @REPLACE \"content\": None\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(  # @KEEP response = client.chat.completions.create(\n",
    "        model=model,  # @REPLACE model=None,\n",
    "        messages=messages,  # @REPLACE messages=None,\n",
    "        temperature=0.7  # @REPLACE temperature=None\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c98b1e",
   "metadata": {},
   "source": [
    "### üéØ Exercise 5: The Executor Agent\n",
    "\n",
    "The `executor_agent` manages the workflow by executing each step of a given plan. It:\n",
    "\n",
    "1. Decides **which agent** (`research_agent`, `writer_agent`, or `editor_agent`) should handle the step.\n",
    "2. Builds context from the outputs of previous steps.\n",
    "3. Sends the enriched task to the selected agent.\n",
    "4. Collects and stores the results in a shared history.\n",
    "\n",
    "üëâ **Do not implement or modify this function.** It is already provided as the orchestration component of the multi-agent pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf2d02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_registry = {\n",
    "    \"research_agent\": research_agent,\n",
    "    \"editor_agent\": editor_agent,\n",
    "    \"writer_agent\": writer_agent,\n",
    "    # puedes agregar m√°s si lo deseas\n",
    "}\n",
    "\n",
    "def clean_json_block(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the contents of a JSON block that may come wrapped with Markdown backticks.\n",
    "    \"\"\"\n",
    "    raw = raw.strip()\n",
    "    # Quitar bloque tipo ```json ... ```\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = re.sub(r\"^```(?:json)?\\n?\", \"\", raw)\n",
    "        raw = re.sub(r\"\\n?```$\", \"\", raw)\n",
    "    return raw.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c41493df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executor_agent(plan_steps: list[str], model: str = \"openai:gpt-4o\"):\n",
    "    history = []\n",
    "\n",
    "    print(\"==================================\")\n",
    "    print(\"üéØ Editor Agent\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    for i, step in enumerate(plan_steps):\n",
    "        # Paso 1: Determinar el agente y la tarea\n",
    "        agent_decision_prompt = f\"\"\"\n",
    "You are an execution manager for a multi-agent research team.\n",
    "\n",
    "Given the following instruction, identify which agent should perform it and extract the clean task.\n",
    "\n",
    "Return only a valid JSON object with two keys:\n",
    "- \"agent\": one of [\"research_agent\", \"editor_agent\", \"writer_agent\"]\n",
    "- \"task\": a string with the instruction that the agent should follow\n",
    "\n",
    "Only respond with a valid JSON object. Do not include explanations or markdown formatting.\n",
    "\n",
    "Instruction: \"{step}\"\n",
    "\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": agent_decision_prompt}],\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "        # üßº Limpieza del bloque JSON\n",
    "        raw_content = response.choices[0].message.content\n",
    "        cleaned_json = clean_json_block(raw_content)\n",
    "        agent_info = json.loads(cleaned_json)\n",
    "\n",
    "        agent_name = agent_info[\"agent\"]\n",
    "        task = agent_info[\"task\"]\n",
    "\n",
    "        # Paso 2: Construir el contexto con outputs anteriores\n",
    "        context = \"\\n\".join([\n",
    "            f\"Step {j+1} executed by {a}:\\n{r}\" \n",
    "            for j, (s, a, r) in enumerate(history)\n",
    "        ])\n",
    "        enriched_task = f\"\"\"You are {agent_name}.\n",
    "\n",
    "Here is the context of what has been done so far:\n",
    "{context}\n",
    "\n",
    "Your next task is:\n",
    "{task}\n",
    "\"\"\"\n",
    "\n",
    "        print(f\"\\nüõ†Ô∏è Executing with agent: `{agent_name}` on task: {task}\")\n",
    "\n",
    "        # Paso 3: Ejecutar el agente correspondiente\n",
    "        if agent_name in agent_registry:\n",
    "            output = agent_registry[agent_name](enriched_task)\n",
    "            history.append((step, agent_name, output))\n",
    "        else:\n",
    "            output = f\"‚ö†Ô∏è Unknown agent: {agent_name}\"\n",
    "            history.append((step, agent_name, output))\n",
    "\n",
    "        print(f\"‚úÖ Output:\\n{output}\")\n",
    "\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_history = executor_agent(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac95cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = executor_history[-1][-1].strip(\"`\")  \n",
    "display(Markdown(md))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
